---
title: "Session 2 — The tidyverse continued: import, tidying, transformation"
author: "Matthew Taylor"
execute:
  dpi: 300
  cache: false
format: 
  html:
    toc: true
    self-contained: true
editor: visual
---

# Setup code

As we did in session 1, run the following chunk (click the green arrow in the corner) which will check that everything we need for today's session is installed and up to date.

```{r setup}
#| echo: false
# Required packages
required_packages <- c("tidyverse", "arrow", "babynames", "curl", "duckdb", "gapminder", 
    "ggrepel", "ggridges", "ggthemes", "hexbin", "janitor", "Lahman", 
    "leaflet", "maps", "nycflights13", "openxlsx", "palmerpenguins", 
    "repurrrsive", "tidymodels", "writexl")

# Install BiocManager if needed
if (!requireNamespace("BiocManager", quietly = TRUE)) {
  install.packages("BiocManager")
}

# Try BiocManager first, then fallback to install.packages
for (pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    message("Trying BiocManager::install('", pkg, "')")
    tryCatch({
      BiocManager::install(pkg, ask = FALSE, update = FALSE)
    }, error = function(e_bioc) {
      message("BiocManager failed. Trying install.packages('", pkg, "')")
      tryCatch({
        install.packages(pkg, dependencies = TRUE)
      }, error = function(e_cran) {
        message("Failed to install '", pkg, "' via both methods.")
      })
    })
  }
}


```

Also, before we start, click on the little gear above the document window and select "clear all output" from the dropdown menu (this prevents any *spoilers!*):

![](images/clipboard-2475862271.png)

# Welcome

Welcome to part 2 of the *foundations of R for bioinformatics* course. Today, we are going to hone our tidyverse skills as we learn how to import, tidy and transform data. You may already wondering what is meant by "tidying" data - can data be *un*tidy? The answer, from the perspective of R, is yes! But more on that later...

We will also take a closer look at an important tidyverse tool that you have already seen in action during session 1 but that I haven’t yet explained properly: the **pipe**. The pipe, written as `%>%` or `|>`, allows us to link together a sequence of functions so that the output of one step becomes the input to the next. Instead of writing long, nested commands that are difficult to read, we can use the pipe to build analyses step by step in a way that mirrors how we think about the task: *take this dataset, then filter it, then summarise it, then plot it.* Using the pipe makes your code more readable, more reproducible, and easier to debug.

As before, this session is heavily inspired by [R for Data Science(2nd Edition)](https://r4ds.hadley.nz/) by Hadley Wickham & Garrett Grolemund. However, **I WILL ALSO BE INCLUDING SOME REAL WORLD RNA SEQ DATA FROM REF** to make the course more applicable to our needs — namely to introduce you to how R can be used for big data/bioinformatics, such an an RNAseq experiment.

## Goals for session 2

By the end of this session, you will be able to:

-   

# Data transformation

## Introduction

In the previous session, we used the `penguins` dataset to create some useful visualisations of different relationships within the data. Often, however, the data you have is not exactly in the correct format to give the insight you want. Maybe the variables are named incorrectly, or you need to summarise the data in a particular way. Here, we will learn how to **transform** data using the **dplyr** package.

### Packages required

First, we shall load the packages we need. `dplyr` is part of the `tidyverse` package, so loading that will be sufficient. We also need the `nycflights` package, and `ggplot2` for plotting (also part of `tidyverse`). Note: these were all installed in our setup chunk, so we just need to load them using the `library` function now.

```{r}
library(tidyverse)
#library(nycflights13)
```

We've been ignoring the output of this till now, but let's just quickly look at what this is telling us.

![](images/clipboard-572882515.png)

This is a warning that the package in question was compiled in a different version of R to the one we are running. Don’t panic — warnings are not errors. If your code runs and plots appear, you’re fine. (The way you would address this would be to update your R installation and re-install the packages; there is no need for us to do this now).

![](images/clipboard-77745967.png)

This part is telling us that the `dplyr` package overwrites some functions in base R. If you want to use the base version of these functions after loading dplyr, you’ll need to use their full names: `stats::filter()` and `stats::lag()`. So far, we’ve mostly ignored which package a function comes from because it doesn’t usually matter. However, knowing the package can help you find help and find related functions, so when we need to be precise about which package a function comes from, we’ll use the same syntax as R: `packagename::functionname()`.

### nycflights13 (maybe)

Within the `nycflights13` package is a dataset called `nycflights13::flights`. This comes from the US Bureau of

### Our dataset

In the Hadley course section on data transformation, they use some built-in data: this time, a dataset on flights which departed New York City in 2013. I've decide to adapt this to instead use data from the UK's own [Civil Aviation Authority (CAA)](https://www.caa.co.uk/data-and-analysis/) - specifically statistics on UK airports from February 2025.

To get the dataset, we can import it directly from their website using the function `read_csv()` from the `tidyverse` package - more on this (and what exactly a 'csv' is) later in the *Data import* section. Remember: using `<-` assigns the code on the right to an object name on the left. There's nothing special about calling it `uk_flights` — we could call it `bananas` if we really wanted — but `uk_flights` is a more useful name for what the data actually is.

```{r import_uk_flights}
uk_flights <- read_csv("https://www.caa.co.uk/Documents/Download/23996/6890c139-9322-4a92-9e12-b6c70d505aa7/17059")

# Fallback in case the URL doesn't work - you can download the data into your current working directory and read it in like this:
# uk_flights <- read_csv("Table_03_Aircraft_Movements.csv")

# I'm also going to remove the first 2 columns, which aren't useful for us:
uk_flights <- uk_flights[, -(1:2)] # this says "subset uk_flights without columns 1 to 2
```

We're also going to convert it quickly into a **tibble.** A tibble is a special type of data frame used by the tidyverse to avoid some common problems. The most important difference between tibbles and data frames is the way tibbles print; they are designed for large datasets, so they only show the first few rows and only the columns that fit on one screen. There are a few options to see everything: `View(uk_flights)` opens an interactive, scrollable, and filterable view. Otherwise you can use `print(uk_flights, width = Inf)` to show all columns, or use `glimpse()`:

```{r convert_and_view}

uk_flights <- tibble(uk_flights)
glimpse(uk_flights)
```

The variable names are followed by abbreviations that tell you the **type** of each variable, which we talked a bit about in session 1: `<int>` is short for integer, `<dbl>` is short for double, `<chr>` for character, and `<dttm>` for date-time. The operations you can perform on a column depend heavily on its “type.”

### dplyr basics

The following sections will introduce you to the fundamental dplyr functions which will solve the majority of your data manipulation challenges. All of these functions have the following in common:

-   The first *argument* of the function (input) is always a data frame

-   The subsequent arguments typically describe which column you want the function to operate on, using the variable name without quotes, e.g., `reporting_airport_name`

-   The output is always a new data frame.

Each function typically does just one thing. Therefore, complex problems typically involve combining these functions one after another, which we do using the **pipe**. I know I keep mentioning this thing without fully explaining it — I'm sorry! — but I promise we will cover this in more detail soon. In brief, the pipe takes the thing on the left and passes it into the function on the right. Think of it as the word "then". That makes it possible to get a sense of the following code even though you haven’t yet learned the details: **Pause: what do you think the output of the following chunk will be? Read it as if reading a sentence "take the uk_flights data frame, then..."**

```{r}
uk_flights %>%
  group_by(reporting_airport_group_name) %>%
  summarise(
    mean_total_flights = round(mean(grand_total, na.rm = TRUE))
  )

```

dplyr’s verbs are organized into four groups based on what they operate on: **rows**, **columns**, **groups**, or **tables**. We will cover these one by one!

## Rows

The 2 most important functions here are:

-   `filter()` - changes which rows are present without changing their order

-   `arrange()` - changes the order of the rows without changing which are present

The columns are left unchanged. Another function is `distinct()` which finds rows with unique values (and can optionally modify the columns, unlike the other 2).

### `filter()`

`filter()` allows you to keep rows based on the values of the columns. The first argument is the data frame. The second and subsequent arguments are the conditions that must be true to keep the row. For example, we could find all airports which reported more than 1000 flights in our dataset.

```{r}
uk_flights %>%
  filter(grand_total > 1000)
```

Notice how we now have a preview of a new data table that satisfies the requirements of our filter — all of the values in the grand_total column are greater than 1000. Note that this hasn't changed our original data (we haven't overwritten it) and we also haven't saved it to a new object, so it literally only exists as a preview below that chunk. If we wanted to overwrite our original (not recommended usually), we would put `uk_flights <-` before that code; or, more likely, to save to a new object, we would put in a new variable name there e.g., `busy_airports <-`:

```{r}
busy_airports <- uk_flights %>%
  filter(grand_total > 1000)
```

This is the key difference between the *assignment operator `<-`* and the pipe `%>%`.

-   `<-` means assign what's on the right to the thing on the left.

-   `%>%` means take what's on the left and do the thing on the right to it.

Back to `filter()`...

As well as `>` (greater than), you can use `>=` (greater than or equal to), `<` (less than), `<=` (less than or equal to), `==` (equal to), and `!=` (not equal to). You can also combine conditions with `&` or `,` to indicate “and” (check for both conditions) or with `|` to indicate “or” (check for either condition):

```{r}
# Airports with more than 1000 flights but less than 2000:
uk_flights %>%
  filter(grand_total > 1000 & grand_total < 2000)
```

```{r}
# Airports which are in London or have more flights than 1000
uk_flights %>%
  filter(
    grand_total > 1000 | reporting_airport_group_name == "London Area Airports")
```

```{r}
# All airports not in London area
uk_flights %>%
  filter(
    reporting_airport_group_name != "London Area Airports")
```

There’s a useful shortcut when you’re combining `|` and `==`, which is `%in%`. It keeps rows where the variable equals one of the values on the right:

```{r}
# Data for Birmingham and Stansted airports
uk_flights %>%
  filter(
    reporting_airport_name %in% c("BIRMINGHAM", "STANSTED")
  )
```

Note that when you want `filter()` to check if something is equal to something, you have to use the double equals `==` rather than single `=`. Basically, this is because R sometimes treats `=` like the assignment operator (as in other languages).

Another mistakes is writing “or” statements like you would in English. We might read the following as "filter the airport names to only include them if they are Birmingham or Stansted." With some variables, this might not throw an error (but still won't give you what you meant). In our case it does:

```{r}
#| error: true
uk_flights %>%
  filter(
    reporting_airport_name == "BIRMINGHAM" | "STANSTED"
  )
```

### `arrange()`

`arrange()` changes the order of the rows based on the value of the columns. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns. In addition, you can use the `desc()` function on a column inside of `arrange()` to re-order the data frame based on that column from largest number to smallest. Say we wanted to sort our airports by the number of military flights:

```{r}
uk_flights %>%
  arrange(desc(military))
```

How would we go from smallest to largest? It turns out, that is the default for `arrange()`. So if we remove `desc()` from the previous example:

```{r}
uk_flights %>%
  arrange(military)
```

Note that the number of rows has not changed – we’re only arranging the data, we’re not filtering it.

**What if we wanted to arrange by number of military flights from lowest to highest, and in the event of ties, to arrange by total number of flights from highest to lowest?**

.

.

.

*Scroll down for answer*

.

.

.

.

.

.

.

.

.

.

```{r}
uk_flights %>%
  arrange(military, desc(grand_total))
```

### **`distinct()`**

`distinct()` finds all the unique rows in a dataset, however dataset is not the best for demonstrating this function as the rows are mostly all unique. If there are any duplicate rows in the data, you can use `distinct()` with no arguments to remove them:

```{r}
# Remove duplicate rows, if any
uk_flights %>%
  distinct()
```

We have no duplicates, so the number of rows isn't changed.

What if we just want to know all what of the different reporting airport groups are?

```{r}
uk_flights %>%
  distinct(reporting_airport_group_name)
```

Notice how we've lost the other columns? This is fine in our case because we just wanted to know the unique values of the reporting_airport_group_name variable. But it is possible to keep the other columns in place using `.keep_all = TRUE`

```{r}
uk_flights %>%
  distinct(reporting_airport_group_name, .keep_all = TRUE)
```

Most of the time, however, you’ll want the distinct combination of some variables, so you can also optionally supply column names. Say now we want to find all the unique combinations of reporting_area_group_name and reporting_airport_name:

```{r}
uk_flights %>%
  distinct(reporting_airport_group_name, reporting_airport_name)
```

I.e,. we now have a quick overview of all of the airports in our dataset and their reporting area group name.

What if we want to know how many of each group there are? In this case, we're betting off using `count()` and we can sort from highest to lowest using `sort = TRUE`.

```{r}
uk_flights %>%
  count(reporting_airport_group_name, sort = TRUE)
```

## Columns

There are 4 important functions which affect the columns without changing the rows:

-   `select()` changes which columns are present

-   `mutate()` creates new columns derived from existing columns

-   `rename()` changes the names of columns

-   `relocate()` changes the positions of columns

### `select()`

`select()` is sort of like the columns version of `filter()` — rather than filtering for rows which fit a certain criteria, we are selecting specific columns.

Select columns by name:

```{r}
uk_flights %>%
  select(reporting_airport_name, grand_total)
```

Select all columns within a range (inclusive):

```{r}
uk_flights %>%
  select(reporting_airport_group_name:air_transport)
```

Select all columns *except* for those within a range:

```{r}
uk_flights %>%
  select(!reporting_airport_group_name:air_transport)
```

`!` reads like "NOT".

Select columns of a specific variable type, e.g., characters

```{r}
uk_flights %>%
  select(where(is.character))
```

There are a number of helper functions you can use within `select()`:

-   `starts_with("abc")`: matches names that begin with “abc”.

-   `ends_with("xyz")`: matches names that end with “xyz”.

-   `contains("ijk")`: matches names that contain “ijk”.

-   `num_range("x", 1:3)`: matches `x1`, `x2` and `x3`.

You can rename variables as you `select()` them by using `=`. The new name appears on the left-hand side of the `=`, and the old variable appears on the right-hand side.

```{r}
uk_flights %>%
  select(airport_name = reporting_airport_name)
```

### `mutate()`

This is a really useful function particularly for calculating new metrics from your data. E.g., suppose you wanted to calculate the percentage of flights at an airport which are related to business aviation. You give the column a name first (`business_percentage`) and write a formula relating to other columns to calculate it:

```{r}
uk_flights %>% 
  mutate(
    business_percentage = business_aviation / grand_total * 100
  )
```

Now we can see that column at the end of the preview. (Note we still haven't changed `uk_flights` itself as we didn't overwrite it using the assignment operator `<-`).

By default, `mutate()` adds new columns on the right-hand side of your dataset, which makes it difficult to see what’s happening here. We can use the `.before` argument to instead add the variables to the left-hand side:

```{r}
uk_flights %>% 
  mutate(
    business_percentage = business_aviation / grand_total * 100,
    .before = 3 # means put it before the third column
  )
```

As you may have guessed, to do the opposite, we use `.after`. You also can specify a particular column rather than just a column number, e.g., if we want to put the new `business_percentage` column after `grand_total`:

```{r}
uk_flights %>% 
  mutate(
    business_percentage = business_aviation / grand_total * 100,
    .after = grand_total 
  )
```

Another useful argument for `mutate()` is `.keep` which allows you to keep certain variables in the final data frame — a great use for this is to specify `"used"` which will only keep the variables used to make the new column:

```{r}
uk_flights %>% 
  mutate(
    business_percentage = business_aviation / grand_total * 100,
    .keep = "used" 
  )
```

However, now we can't see what airport we're referring to! **How could we fix this? (hint: will need to use 2 functions (`mutate()` and `select()`) and pipes).**

.

.

.

*Scroll down for answer*

.

.

.

*.*

.

.

.

.

.

.

`.keep` *only accepts one of these fixed keywords:*

-   `"all"` *(keep all existing columns, the default)*

-   `"used"` *(keep only columns used to make the new variables)*

-   `"unused"` *(drop those used, keep the rest)*

-   `"none"` *(drop all original columns, keep only the new ones)*

*So you would have to do this sequentially using `mutate()` then `select()`:*

```{r}
uk_flights %>% 
  mutate(
    business_percentage = business_aviation / grand_total * 100) %>% 
  select(
    reporting_airport_name, business_aviation, grand_total, business_percentage)
```

### `rename()`

`select()` removes all of the other columns you haven't selected. If you want to keep them all but just rename a few:

```{r}
uk_flights %>%
  rename(
    airport_name = reporting_airport_name, 
    reporting_group = reporting_airport_group_name)
```

If you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out `janitor::clean_names()` which provides some useful automated cleaning.

### `relocate()`

`relocate()` moves columns around. You might want to collect related variables together or move important variables to the front. By default `relocate()` moves variables to the front:

```{r}
uk_flights %>%
  relocate(grand_total, business_aviation)
```

You can also specify where to put them using the `.before` and `.after` arguments, just like in `mutate()`:

```{r}
uk_flights %>%
  relocate(official:business_aviation, .after = reporting_airport_name)
```

## The pipe

The **pipe** is one of the most powerful tools in the tidyverse. It takes the result of one step and passes it as the first argument to the next function. You’ve already seen simple examples, but its *real power* appears when we want to combine multiple steps.

Suppose we want to find the airport, outside of the London area, with the highest percentage of official flights. To do this, we need to:

-   `filter()` for airports not in the *London Area Airports* category

-   Create a new column (`mutate()`) giving us the percentage of official flights

-   `select()` just the columns we want to show, and

-   `arrange()` by the percentage of official flights from high to low.

Without the pipe, we have two options:

1.  **Nesting functions** (ugly, hard to read, and a pain to type):

```{r}
arrange(
  select(
    mutate(
      filter(
        uk_flights, # here is our data frame - look how tucked away it is!!
        reporting_airport_group_name != "London Area Airports"
      ),
      official_percentage = official / grand_total * 100
    ),
    reporting_airport_name, official_percentage
  ),
  desc(official_percentage)
)
```

2.  **Creating lots of intermediate objects** (clearer, but verbose):

```{r}
uk_flights_1 <- filter(uk_flights, reporting_airport_group_name != "London Area Airports")
uk_flights_2 <- mutate(uk_flights_1, official_percentage = official / grand_total * 100)
uk_flights_3 <- select(uk_flights_2, reporting_airport_name, official_percentage)
arrange(uk_flights_3, desc(official_percentage))
```

If we use the pipe instead, we get this:

```{r}
uk_flights %>% # take our data frame uk_flights
  filter(reporting_airport_group_name != "London Area Airports") %>% # filter it
  mutate(official_percentage = official / grand_total * 100) %>% # add new column
  select(reporting_airport_name, official_percentage) %>% # select columns we want
  arrange(desc(official_percentage)) # sort by official percentage descending
  
```

This version reads like a sentence: *“Take the flights data, then filter, then mutate, then select, then arrange.”* It’s easier to type, avoids awkward brackets and commas, and because the data is piped in from the start, RStudio’s autocomplete works smoothly with column names.

## Groups

So far you’ve learned about functions that work with rows and columns. dplyr gets even more powerful when you add in the ability to work with groups. In this section, we’ll focus on the most important functions: `group_by()`, `summarize()`, and the slice family of functions.

### `.group_by()`

This function allows you to subdivide your dataset into groups which are useful for further analysis. E.g., we know we have multiple airports per *reporting_airport_group_name* so we could group by this variable:

```{r}
uk_flights %>%
  group_by(reporting_airport_group_name)
```

Nothing major has happened there, except we now see that all of the London Area Airports are together, all of the Non UK Reporting Airports are together etc. You may also notice the output indicates what we are grouped by: ![](images/clipboard-727697052.png){width="289"} This means that subsequent operations (if we piped further) are applied per Group. We will see this in action in the next section.

### `summarise()`

The most important grouped operation is a summary, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group. In dplyr, this operation is performed by `summarise()`.

```{r}
uk_flights %>%
  group_by(reporting_airport_group_name) %>%
  summarise(
    avg_total_flights = round(mean(grand_total, na.rm = TRUE))
  )
```

*Note that I have included `na.rm = TRUE`* *within the `mean()`* *function - this was just in case we had missing data, which would have resulted in NA being the output of `mean()`*. *In our dataset, we didn't have to worry about this, you may need to worry about NAs in data you get elsewhere. We don't have time to go into detail about handling missing values in this course, so for more information, see [Chapter 18](https://r4ds.hadley.nz/missing-values.html) of the Hadley course.*

You can create any number of summaries in a single call to `summarise()`; one very useful summary is `n()`, which returns the number of rows in each group:

```{r}
uk_flights %>%
  group_by(reporting_airport_group_name) %>%
  summarise(
    avg_total_flights = round(mean(grand_total, na.rm = TRUE)),
    n = n()
  )
```

### The `slice_` functions

There are five handy functions that allow you to extract specific rows within each group:

-   `df |> slice_head(n = 1)` takes the first row from each group.

-   `df |> slice_tail(n = 1)` takes the last row in each group.

-   `df |> slice_min(x, n = 1)` takes the row with the smallest value of column `x`.

-   `df |> slice_max(x, n = 1)` takes the row with the largest value of column `x`.

-   `df |> slice_sample(n = 1)` takes one random row.

You can vary `n` to select more than one row, or instead of `n =`, you can use `prop = 0.1` to select (e.g.) 10% of the rows in each group.

Example: finding the busiest airports for each reporting group.

```{r}
uk_flights %>%
  group_by(reporting_airport_group_name) %>%
  slice_max(grand_total, n = 1) %>%
  relocate(grand_total)
```

This is similar to computing the busiest airport with `summarise()`, but you get the whole corresponding row (or rows if there’s a tie) instead of the single summary statistic.

### Grouping by multiple variables

You can create groups using more than one variable. Our data doesn't work particularly well in this example, so let's make a new variable first. We'll call an airport "busy" if it saw more than 5000 flights in this reporting period:

```{r}
uk_flights <- uk_flights %>% # we want to actually add this column to our data
  mutate(busy = ifelse(grand_total > 5000, "busy", "not_busy"))
```

Now let's say we want to group by the reporting airport group name and our new busy variable:

```{r}
busy_areas <- uk_flights %>%
  group_by(reporting_airport_group_name, busy) %>%
  relocate(busy, .after = reporting_airport_name)

busy_areas
```

When you summarize a tibble grouped by more than one variable, each summary peels off the last group. To make it obvious what’s happening, dplyr displays a message that tells you how you can change this behavior:

```{r}
busy_n <- busy_areas %>%
  summarise(n = n())

busy_n
```

If you’re happy with this behavior, you can explicitly request it in order to suppress the message:

```{r}
busy_n <- busy_areas %>%
  summarise(n = n(),
            avg_flights = round(mean(grand_total, na.rm = TRUE)),
            .groups = "drop_last")

busy_n
```

Alternatively, change the default behavior by setting a different value, e.g., `"drop"` to drop all grouping or `"keep"` to preserve the same groups.

### Ungrouping

You might also want to remove grouping from a data frame without using `summarize()`. You can do this with `ungroup()`.

```{r}
busy_areas %>% 
  ungroup()
```

Now let’s see what happens when you summarise an ungrouped data frame:

```{r}
busy_areas %>%
  ungroup() %>%
  summarise(
    avg_flights = round(mean(grand_total, na.rm = TRUE)),
    n = n()
  )

```

Now we just have a single row because dplyr is treating them all as belonging to one group.

### `.by`

If you want to combine some of the above steps (grouping and then summarising) into one, dplyr also includes an experimental feature called `.by`. So say you want to summarise the mean number of flights, grouping both by the area of the airport and the "busy-ness":

```{r}
uk_flights %>%
  summarise(
    avg_flights = round(mean(grand_total, na.rm = TRUE)),
    n = n(), 
    .by = c(reporting_airport_group_name, busy)
  )
```

`.by` works with all of these functions and has the advantage that you don’t need to use the `.groups` argument to suppress the grouping message or `ungroup()` when you’re done.

## Tables - using joins

Due to time constraints, I am only going to be able to briefly go over some of the dplyr functions which work on tables. For a more detailed overview, see [*Chapter 19*](https://r4ds.hadley.nz/joins.html) of the Hadley course. Their worked example, using the `nycflights13` package, is also much more involved than our one!

We shall close off this *Data transformation* section by bringing together what we have learned so far, add in the ability to use **joins**, and ask the question: **which airports in our dataset had the highest percentage of cancelled flights, per reporting region?**

---

It’s rare that a data analysis involves only a single data frame. Typically you have many data frames, and you must **join** them together to answer the questions that you’re interested in.

In our case, are using data from the CAA for the number of flights of different categories across UK airports. It would be nice also if we could see, for example, the number of cancelled flights per airport. Unfortunately, our data frame does not include this information. Fortunately, the CAA *does* record this information — but it is in a *separate* file.

Let's import it into Rstudio now:

```{r cancelled}
cancelled <- read_csv("https://www.caa.co.uk/Documents/Download/23996/6890c139-9322-4a92-9e12-b6c70d505aa7/17062")

# Fallback in case the URL doesn't work - you can download the data into your current working directory and read it in like this:
# cancelled <- read_csv("Table_04a_Cancelled_Movements.csv")

# Again, I'm also going to remove the first 2 columns, which aren't useful for us:
cancelled <- cancelled[, -(1:2)] 

# And convert to a tibble

cancelled <- tibble(cancelled)
```

We can have a look at what is in this new dataset:

```{r}
glimpse(cancelled)
```

Immediately, something might stand out to you: 2 of those column names (reporting_airport_group_name and reporting_airport_name) are identical to 2 of the columns we had in our other dataset. This is good news for joining purposes!

The most common form of join is `left_join()` which is special because the output will always have the same rows as the data frame you are joining *to*.

By default, `left_join()` will use all variables that appear in both data frames as the join key, the so called **natural** join. In our case, both `reporting_airport_group_name` and `reporting_airport_name` appear in each dataset, so the join will use both of these to try and match the datasets:

```{r}
uk_flights %>%
  left_join(cancelled)
```

Now we can see all of the other columns within `cancelled` have been added to the `uk_flights` data frame using the `reporting_airport_group_name` and `reporting_airport_name` to find matching **keys.** Note also the presence of some NAs in our data now. **Where have they come from?**

.

.

.

*Scroll down for answer*

.

.

.

.

.

.

.

.

.

*You may have noticed when looking at our new `cancelled`* *data frame that we only have 50 rows compared to the 57 before.* *To make this explicit:*

```{r}
dim(uk_flights) # 57 rows, 15 columns
dim(cancelled) # 50 rows, 5 columns
```

*This means that some of our airports didn't collect information on the number of cancelled flights — so when we join the datasets, this is reflected by the values of NA.*

We might only care about matching by one specific variable in our data. For this, we can use the `join_by()` function:

```{r}
uk_flights %>%
  left_join(cancelled,
            join_by(reporting_airport_name))
```

Additionally, we might only care to join certain columns into our data frame. We can use a pipe nested within our `left_join()` function to achieve this (note that at least one of the columns we select has to match a column in our destination dataset). We will do this to select the `total_cancelled_atms` column from the `cancelled` data frame and join it to our `uk_flights` data frame by matching `reporting_airport_name`, and make a new data frame called `uk_flights_detailed`

```{r}
uk_flights_detailed <- uk_flights %>%
  left_join(cancelled %>% select(reporting_airport_name,total_cancelled_atms))

uk_flights_detailed
```

One other thing you may have spotted is that even some of the airports that *are* included in our `cancelled` data frame have just a dash "-" instead of a number for `total_cancelled_atms`. This causes 2 problems, one of which is already present:

-   The presence of a single character element in a column causes the whole variable to become the type "character", meaning basically that numbers are not being treated as numbers.

-   The above, and the presence of "-", would therefore mess things up if we tried to do sums on this column, such as calculating the mean.

To address this, we can use `mutate()` again, but this time rather than creating a whole new column, we can just edit the `total_cancelled_atms` column. We shall replace the "-" with NA (easier to omit when doing maths) and change the whole column type to numeric. We want to overwrite our old data frame, so we will also need to use the assignment operator `<-`:

```{r}
uk_flights_detailed <- uk_flights_detailed %>%
  mutate(
    total_cancelled_atms = na_if(total_cancelled_atms, "-"),
    total_cancelled_atms = as.numeric(total_cancelled_atms)
  )
  
uk_flights_detailed
```

We are now ready to put together what we have learned to answer the question at the start of this section: **which airports in our dataset had the highest percentage of cancelled flights, per reporting region?** Have a go yourself first, and if you get stuck or want to check you are right, scroll down for a model answer.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

```{r}
uk_flights_detailed %>%
  mutate(percentage_cancelled = total_cancelled_atms / grand_total * 100) %>% # make a new column with percentage cancelled flights
  group_by(reporting_airport_group_name) %>% # group by the area
  slice_max(percentage_cancelled, n = 1) %>% # take the highest number
  select(reporting_airport_group_name, reporting_airport_name, percentage_cancelled) # select just the columns you want to display
```

# Applying what we've learned to RNAseq data (probably session 3 actually)
